<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>首页 on 算法学习笔记</title>
    <link>https://ikingye.github.io/study-algs/</link>
    <description>Recent content in 首页 on 算法学习笔记</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://ikingye.github.io/study-algs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>1.3.1 排序算法</title>
      <link>https://ikingye.github.io/study-algs/docs/advanced/common/sort/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/advanced/common/sort/</guid>
      <description>排序算法 #  </description>
    </item>
    
    <item>
      <title>4.1 教程</title>
      <link>https://ikingye.github.io/study-algs/docs/appendix/tutorial/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/appendix/tutorial/</guid>
      <description>算法教程 #  基础 #  labuladong/fucking-algorithm #  手把手撕 LeetCode 题目，扒各种算法套路的裤子， not only how，but also why. English version supported! https://labuladong.gitbook.io/algo/
youngyangyang04/leetcode-master #  LeetCode 刷题攻略
donnemartin/interactive-coding-challenges #  120+ interactive Python coding interview challenges (algorithms and data structures). Includes Anki flashcards.
(book)kevin-wayne/algs4 #  Algorithms, 4th edition textbook code and libraries
 进阶 #  </description>
    </item>
    
    <item>
      <title>LRU Cache</title>
      <link>https://ikingye.github.io/study-algs/docs/advanced/common/lru/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/advanced/common/lru/</guid>
      <description>LRU Cache #  LRU 全称是 Least Recently Used，即最近最久未使用的意思。
LRU 算法的设计原则是：如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小。 也就是说，当限定的空间已存满数据时，应当把最久没有被访问到的数据淘汰。
LRU-K #  LRU-K 中的 K 代表最近使用的次数，因此 LRU 可以认为是 LRU-1。
LRU-K 的主要目的是为了解决 LRU 算法 “缓存污染” 的问题， 其核心思想是将 “最近使用过 1 次” 的判断标准扩展为 “最近使用过 K 次”。
Redis 的 LRU 实现 #  如果按照 HashMap 和双向链表实现，需要额外的存储存放 next 和 prev 指针，牺牲比较大的存储空间，显然是不划算的。所以 Redis 采用了一个近似的做法，就是随机取出若干个 key，然后按照访问时间排序后，淘汰掉最不经常使用的，具体分析如下：
为了支持 LRU，Redis 2.8.19 中使用了一个全局的 LRU 时钟，server.lruclock，定义如下，
#define REDIS_LRU_BITS 24 unsigned lruclock:REDIS_LRU_BITS; /* Clock for LRU eviction */ 默认的 LRU 时钟的分辨率是 1 秒，可以通过改变 REDIS_LRU_CLOCK_RESOLUTION 宏的值来改变，Redis 会在 serverCron() 中调用 updateLRUClock 定期的更新 LRU 时钟，更新的频率和 hz 参数有关，默认为 100ms 一次，如下，</description>
    </item>
    
    <item>
      <title>paxos</title>
      <link>https://ikingye.github.io/study-algs/docs/advanced/common/paxos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/advanced/common/paxos/</guid>
      <description>paxos #  </description>
    </item>
    
    <item>
      <title>raft</title>
      <link>https://ikingye.github.io/study-algs/docs/advanced/common/raft/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/advanced/common/raft/</guid>
      <description>raft #  </description>
    </item>
    
    <item>
      <title>树</title>
      <link>https://ikingye.github.io/study-algs/docs/advanced/common/tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/advanced/common/tree/</guid>
      <description>树 #  判断一棵树是否包含另一棵树的结构 #  使用树结构序列化的方法，将两棵树进行相同方式的序列化，然后利用 kmp 判断子串，则可以得到
结果，时间复杂度为 O（m+n）
这道题的可行性是：树结构的序列化和反序列化是一一对应的
 </description>
    </item>
    
    <item>
      <title>4.2 面试题</title>
      <link>https://ikingye.github.io/study-algs/docs/appendix/interview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/appendix/interview/</guid>
      <description>算法面试题 #  基础题 #  进阶题 #  </description>
    </item>
    
    <item>
      <title>KMP</title>
      <link>https://ikingye.github.io/study-algs/docs/advanced/common/kmp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/advanced/common/kmp/</guid>
      <description>KMP #  KMP 是用来找字符串匹配的
KMP 的时间复杂度是 O (m + n)
参考 #   如何更好地理解和掌握 KMP 算法？ KMP 算法详解 Knuth-Morris-Pratt algorithm  KMP：花 48 小时看懂了 KMP，想让你在 48 分钟内看懂    </description>
    </item>
    
    <item>
      <title>布隆过滤器</title>
      <link>https://ikingye.github.io/study-algs/docs/advanced/common/bloom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/advanced/common/bloom/</guid>
      <description>布隆过滤器 #  布隆过滤器（Bloom Filter）是 1970 年由布隆提出的。 它实际上是一个很长的二进制向量和一系列随机映射函数。 布隆过滤器可以用于检索一个元素是否在一个集合中。 它的优点是空间效率和查询时间都比一般的算法要好的多， 缺点是有一定的误识别率和删除困难。
解决： 网页 URL 去重、垃圾邮件识别、大集合中重复元素的判断和缓存穿透等问题
本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 某样东西一定不存在或者可能存在。
相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。
HashMap 的问题 #    例如存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，那 HashMap 占据的内存大小就变得很可观了。
  还比如说你的数据集存储在远程服务器上，本地服务接受输入，而数据集非常大不可能一次性读进内存构建 HashMap 的时候，也会存在问题。
  布隆过滤器的原理 #  当一个元素被加入集合时，通过 K 个散列函数将这个元素映射成一个位数组中的 K 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：如果这些点有任何一个 0，则被检元素一定不在；如果都是 1，则被检元素很可能在。
 应用 #  在大数据场景应用比较多，比如 Hbase 中使用它去判断数据是否在磁盘上。
还有在爬虫场景判断 url 是否已经被爬取过。
在缓存之前在加一层 BloomFilter #  </description>
    </item>
    
    <item>
      <title>递归</title>
      <link>https://ikingye.github.io/study-algs/docs/basic/thought/recursive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/basic/thought/recursive/</guid>
      <description>递归 #  参考 #   三道题套路解决递归问题  </description>
    </item>
    
    <item>
      <title>4.3 关注项目</title>
      <link>https://ikingye.github.io/study-algs/docs/appendix/attention/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ikingye.github.io/study-algs/docs/appendix/attention/</guid>
      <description>关注项目 #  </description>
    </item>
    
  </channel>
</rss>
